behaviors:
  MazeAgent:  # Asegúrate que coincida con Behavior Name en tu Agent prefab (cámbialo si usas "RLAgent")
    trainer_type: ppo
    hyperparameters:
      batch_size: 512  # Opt: Baja para updates más frecuentes en nav
      buffer_size: 51200  # Opt: Aumenta para más diversidad en mazes
      learning_rate: 3.0e-4
      beta: 5.0e-3  # Opt: Aumenta para exploración en entornos con traps/doors
      epsilon: 0.2
      lambd: 0.95
      num_epoch: 3
      learning_rate_schedule: linear

    network_settings:
      normalize: true  # Opt: Esencial para obs posicionales/vel (tuyas en RLAgentAdapter)
      hidden_units: 256
      num_layers: 2  # Prueba 3 si no converge
      vis_encode_type: simple  # Mantén si planeas añadir rays/vision

    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0

    keep_checkpoints: 5
    max_steps: 5.0e6
    time_horizon: 64
    summary_freq: 10000

environment_parameters:  # Fix: Anida min/max bajo sampler_parameters para compatibilidad v1.0
  maze_seed:  # Ejemplo: Usa en RLAgentAdapter.OnEpisodeBegin para randomizar seed (e.g., Random.InitState((int)Academy.Instance.EnvironmentParameters.GetWithDefault("maze_seed", 0)))
    sampler_type: uniform
    sampler_parameters:
      min: 0
      max: 10000

env_settings:
  num_envs: 1  # Override en CLI para paralelo

engine_settings:
  time_scale: 50  # Opt: Acelera; baja si CPU issue
  width: 84
  height: 84
  quality_level: 1
  capture_frame_rate: 60
  no_graphics: false  # Cambia a true para headless si build

torch_settings:
  device: "cuda"  # Bueno si GPU; prueba "cpu" si error